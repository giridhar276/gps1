{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDs9DRHeU0lA"
   },
   "source": [
    "#Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fo9M10uMU5Ea"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71ErFfpWi9nh"
   },
   "source": [
    "# LLMs Lab-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGc-TSgxXaKJ"
   },
   "source": [
    "# Accessing OpenAI LLM through an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PJMbqMOCYkTY"
   },
   "outputs": [],
   "source": [
    "#!pip3 install OpenAI #llm\n",
    "##!pip3 install langchain\n",
    "#!pip3 install langchain_community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k4c9gz6sXiKX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"sk-6YQXIgD11EZLTp3C2OLvZOMxCnCyTyNM6DQUlLskVtT3BlbkFJ-a-CrSMiA-0CS3iCEJKw1b4JC9JezL2iAy1HWFCTUA\"\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TNdgXtrZXu5_"
   },
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain.llms\n",
    "dir(langchain.llms )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm= OpenAI()\n",
    "\n",
    "print(llm.invoke(\"How many minimum sleeping hours you should have?give single liner\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#my program ----->langchain framework -----> API -----> openai llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Umq0iTHh4zD5"
   },
   "outputs": [],
   "source": [
    "print(llm.invoke(\"What is the sentiment of this review. Give one word answer Pos or Neg - The staff was friendly and helpful. I had a great experience with my loan officer.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VYg-LmG7FDg7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of log messages\n",
    "log_messages = [\n",
    "    \"INFO: Server started successfully\",\n",
    "    \"WARNING: Low disk space\",\n",
    "    \"CRITICAL: Database connection failed\",\n",
    "    \"CRITICAL: Security breach detected\",\n",
    "    \"INFO: New feature released\",\n",
    "]\n",
    "\n",
    "# Create a DataFrame with 10 rows and 1 column\n",
    "df = pd.DataFrame(log_messages, columns=[\"Message\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QmNRAj2IGDUe"
   },
   "outputs": [],
   "source": [
    "# Classify each log message using llm.invoke\n",
    "df[\"Sentiment\"] = df[\"Message\"].apply(lambda message: llm.invoke(f\"Classify the severity of this log message make give output as CRITICAL if the message is critical. give one word answer: {message}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZSf-VSlNGUOg"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "newdf = pd.read_csv(\"statements.csv\")\n",
    "# Classify each log message using llm.invoke\n",
    "newdf\n",
    "newdf[\"Sentiment\"] = newdf[\"Message\"].apply(lambda message: llm.invoke(f\"Classify the statement and give output as positive or negative give one word answer: {message}\"))\n",
    "newdf.to_csv(\"sentimentanalysis.csv\")\n",
    "newdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install Cohere #llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ['COHERE_API_KEY'] = \"yourkey\"\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import  Cohere\n",
    "\n",
    "llm=Cohere()\n",
    "print(llm.invoke(\"How many minimum sleeping hours you should have?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my program -----> API -----> cohere llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm.invoke(\"What is the sentiment of this review. Give one word answer Pos or Neg - The staff was friendly and helpful. I had a great experience with my loan officer.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a list of log messages\n",
    "log_messages = [\n",
    "    \"INFO: Server started successfully\",\n",
    "    \"WARNING: Low disk space\",\n",
    "    \"CRITICAL: Database connection failed\",\n",
    "    \"CRITICAL: Security breach detected\",\n",
    "    \"INFO: New feature released\",\n",
    "]\n",
    "\n",
    "# Create a DataFrame with 10 rows and 1 column\n",
    "df = pd.DataFrame(log_messages, columns=[\"Message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify each log message using llm.invoke\n",
    "df[\"Sentiment\"] = df[\"Message\"].apply(lambda message: llm.invoke(f\"Classify the severity of this log message make give output as CRITICAL if the message is critical: {message}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34tmhRkC3UwI"
   },
   "source": [
    "# Gen AI - Code Generation in Google Colab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fFNYpN7T3dS-"
   },
   "source": [
    "Import dataset from https://raw.githubusercontent.com/giridhar276/Datasets/master/Automobile%20Data%20Set/AutoDataset.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MuKH7m8mtU66"
   },
   "source": [
    "print number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQcH7mf_taKN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FetJeAZ7ta8F"
   },
   "source": [
    "Print the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DR0PGk8UtdyT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kz3MastkteiW"
   },
   "source": [
    "Create a bar chart for the 'fuel-type' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rnOE_ce8tk4J"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W6KInBkHtlvF"
   },
   "source": [
    "Findout outliers in price column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jg3j4192tro5"
   },
   "outputs": [],
   "source": [
    "import langchain.llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(langchain.llms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM////38NF54/QEhNgT4/i8",
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
